{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"2022-0418_recipie158.ipynb","provenance":[{"file_id":"https://github.com/cedro3/Style_edit/blob/master/Style_edit.ipynb","timestamp":1649739095000}],"collapsed_sections":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"cells":[{"cell_type":"code","source":["# GC mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"FrFSV6ovLtFT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ディレクトリ作成（tfrecord,train_data,val_data）\n","%cd /content\n","!mkdir train_data\n","!mkdir val_data"],"metadata":{"id":"2Q2aU9Qm18j_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tfrecordの内容を展開(あらかじめGdrive内にデータセットをDLしておく)\n","!cp \"/content/drive/MyDrive/Colab Notebooks/note_Axross/_data/tfrecord.zip\" .\n","!unzip tfrecord.zip -d tfrecord"],"metadata":{"id":"1w7W06CYs-x5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 学習データの内容を展開\n","!cp \"/content/drive/MyDrive/Colab Notebooks/note_Axross/_data/test_data.zip\" .\n","!unzip test_data.zip"],"metadata":{"id":"MERvrDbyKruD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Protocol Buffersのインストール\n","!curl -OL https://github.com/google/protobuf/releases/download/v3.15.6/protoc-3.15.6-linux-x86_64.zip\n","!unzip protoc-3.15.6-linux-x86_64.zip -d protoc3\n","!sudo mv protoc3/bin/* /usr/local/bin/\n","!sudo mv protoc3/include/* /usr/local/include/\n","!rm -rf protoc3 protoc-3.15.6-linux-x86_64.zip"],"metadata":{"id":"cHMxBFeZrdwJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ライブラリのインストール\n","!pip install \"opencv-python-headless<4.3\""],"metadata":{"id":"3-qRjWOREiMc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tensorflow/modelsのダウンロード\n","!git clone --depth 1 https://github.com/tensorflow/models\n","%cd /content/models/research\n","!/usr/local/bin/protoc object_detection/protos/*.proto --python_out=."],"metadata":{"id":"_Lpb5dML0Pn-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Object Detection APIに必要なライブラリのインストール\n","!cp /content/models/research/object_detection/packages/tf2/setup.py .\n","!python -m pip install ."],"metadata":{"id":"zClgbcRg0lx5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# インストールの成否確認（Object Detection API）\n","!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"],"metadata":{"id":"FFw1H-jn1SBu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 学習データと評価データの分割\n","\n","# データ格納先の定義\n","original_data_dir = '/content/tfrecord'\n","train_data_dir = '/content/train_data'\n","val_data_dir = '/content/val_data'\n","\n","# ファイル数カウント\n","import glob\n","file_count = len(glob.glob(original_data_dir + '/*.tfrecord'))\n","print('File count : ' + str(file_count))\n","\n","# 学習データ/検証データを80%：20%の割合で分割\n","import random\n","import shutil\n","\n","train_ratio = 0.80\n","\n","file_list = glob.glob(original_data_dir + '/*.tfrecord')\n","random_sample_list = random.sample(file_list, file_count)\n","\n","# ディレクトリへコピー\n","for index, filepath in enumerate(random_sample_list):\n","    if index < int(file_count * train_ratio):\n","        # 学習データ\n","        shutil.copy2(filepath, train_data_dir)\n","    else:\n","        # 検証データ\n","        shutil.copy2(filepath, val_data_dir)"],"metadata":{"id":"U8uFFOAV62T_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 事前学習済モデルのデータ格納先\n","%cd /content\n","!mkdir pretrained_model"],"metadata":{"id":"kTePNtSr7vLs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 事前学習済モデルのダウンロード\n","!wget -P pretrained_model http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","!tar -xvf pretrained_model/efficientdet_d0_coco17_tpu-32.tar.gz -C pretrained_model\n","!rm pretrained_model/efficientdet_d0_coco17_tpu-32.tar.gz"],"metadata":{"id":"cH6kLtcN73O0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# パイプラインコンフィグの置換\n","!cp \"/content/drive/MyDrive/Colab Notebooks/note_Axross/_data/pipeline.config\" \"/content/pretrained_model/efficientdet_d0_coco17_tpu-32\""],"metadata":{"id":"NzZ0bH6W1_79"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# モデルのチェックポイント格納ディレクトリ作成\n","%cd /content\n","!mkdir model_check_point"],"metadata":{"id":"33-WvzJ59MpQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tensorboard起動\n","%load_ext tensorboard"],"metadata":{"id":"gdecESGH9dIh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tensorboard起動\n","tensorboard --logdir /content/model_check_point"],"metadata":{"id":"N7VOfzq4-atp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# モデル訓練\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path=\"/content/pretrained_model/efficientdet_d0_coco17_tpu-32/pipeline.config\" \\\n","    --model_dir=\"/content/model_check_point\" \\\n","    --num_train_steps=1000 \\"],"metadata":{"id":"iR05r8U8-k4k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# モデルのエクスポート\n","!python /content/models/research/object_detection/exporter_main_v2.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path=\"/content/pretrained_model/efficientdet_d0_coco17_tpu-32/pipeline.config\" \\\n","    --trained_checkpoint_dir=\"/content/model_check_point\" \\\n","    --output_directory=\"/content/model_check_point/output\""],"metadata":{"id":"DSfZywcVFxcs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# モデルの読込\n","import tensorflow as tf\n","model_path = '/content/model_check_point/output/saved_model'\n","DEFAULT_FUNCTION_KEY = 'serving_default'\n","loaded_model = tf.saved_model.load(model_path)\n","inference_func = loaded_model.signatures[DEFAULT_FUNCTION_KEY]"],"metadata":{"id":"n9cD9E2b_7SR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# テストデータの閲覧（推論対象のテスト画像）\n","import glob\n","import copy\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","test_data_dir = '/content/test_data'\n","testfile_list = sorted(glob.glob(test_data_dir + '/*.jpg'))"],"metadata":{"id":"BtzflWx_AeKm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 推論（推論用関数）\n","def run_inference_single_image(image, inference_func):\n","    tensor = tf.convert_to_tensor(image)\n","    output = inference_func(tensor)\n","\n","    output['num_detections'] = int(output['num_detections'][0])\n","    output['detection_classes'] = output['detection_classes'][0].numpy()\n","    output['detection_boxes'] = output['detection_boxes'][0].numpy()\n","    output['detection_scores'] = output['detection_scores'][0].numpy()\n","    return output"],"metadata":{"id":"r4Ve1I_aApbI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 結果動画の書出し\n","import cv2\n","import numpy as np\n","from PIL import Image\n","\n","filenames = []\n","\n","temp_image = cv2.imread(testfile_list[0], cv2.IMREAD_UNCHANGED)\n","image_width, image_height = temp_image.shape[1], temp_image.shape[0]\n","fourcc = 'mp4v'\n","writer_fourcc = cv2.VideoWriter_fourcc(*fourcc)\n","videowriter = cv2.VideoWriter('result.mp4', writer_fourcc, 10, (image_width, image_height))\n","\n","# 推論\n","for filecount, testfile in enumerate(testfile_list):\n","    image = cv2.imread(testfile, cv2.IMREAD_UNCHANGED)\n","    debug_image = copy.deepcopy(image)\n","\n","    image_width, image_height = image.shape[1], image.shape[0]\n","    image = image[:, :, [2, 1, 0]]  # BGR形式からRGB形式へ変換\n","    image_np_expanded = np.expand_dims(image, axis=0)\n","\n","    output = run_inference_single_image(image_np_expanded, inference_func)\n","\n","    num_detections = output['num_detections']\n","    for i in range(num_detections):\n","        score = output['detection_scores'][i]\n","        bbox = output['detection_boxes'][i]\n","        # class_id = output['detection_classes'][i].astype(np.int)\n","\n","        if score < 0.85:\n","            continue\n","\n","        x1, y1 = int(bbox[1] * image_width), int(bbox[0] * image_height)\n","        x2, y2 = int(bbox[3] * image_width), int(bbox[2] * image_height)\n","\n","        # 推論結果描画\n","        cv2.rectangle(debug_image, (x1, y1), (x2, y2), (255, 255, 255), 2)\n","        cv2.putText(debug_image, str('{:.2f}'.format(score)), (x1, y1-10), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 255, 255), 2, cv2.LINE_AA)\n","        cv2.rectangle(debug_image, (x1, y1), (x2, y2), (255, 255, 255), 2)\n","    videowriter.write(debug_image)\n","videowriter.release()"],"metadata":{"id":"tgT9u8mFE5OV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 結果動画の再生\n","import imageio\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","\n","def play_video(video, interval=100):\n","    video = imageio.mimread(video)\n","    fig = plt.figure(figsize=(9, 6))\n","\n","    movie = []\n","    for i in range(len(video)):\n","        img = plt.imshow(video[i], animated=True)\n","        plt.axis('off')\n","        movie.append([img])\n","\n","    anime = animation.ArtistAnimation(fig, movie, interval=interval, repeat_delay=1000)\n","    plt.close()\n","    return anime\n","\n","HTML(play_video('result.mp4').to_html5_video())"],"metadata":{"id":"ErEbkEouA2kP"},"execution_count":null,"outputs":[]}]}