{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-0226_recipie032.ipynb","private_outputs":true,"provenance":[{"file_id":"1NmuHX0sUEGg2NhWKJjmWhkHow8SXrpoG","timestamp":1652100501121}],"collapsed_sections":[],"authorship_tag":"ABX9TyOy+Rd6VXWJh7WRbEQ6sUWu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BLyr3QE5vGo4"},"outputs":[],"source":["# パッケージのダウンロード・インポート\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torchvision\n","from torchvision import transforms\n","from torchvision.utils import save_image\n","import matplotlib.pyplot as plt\n","import os\n","%matplotlib inline"]},{"cell_type":"code","source":["# Epochの指定\n","epochs = 500\n","batch_size = 256"],"metadata":{"id":"pLuG-VasvVBJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataset読込\n","transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","dataset = torchvision.datasets.CIFAR10(root=\"./data\",\n","                                            train=True, download=True,\n","                                            transform=transform)\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n","                                               shuffle=True, pin_memory=True)"],"metadata":{"id":"KlR3N4APvZ8k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# データラベル\n","datas = torchvision.datasets.CIFAR10(root=\"./data\",\n","                                            train=True, download=True,\n","                                            transform=None)\n","label_list = [\n","    'airplane',\n","    'automobile',\n","    'bird',\n","    'cat',\n","    'deer',\n","    'dog',\n","    'frog',\n","    'horse',\n","    'ship',\n","    'truck'\n","]\n","\n","img_num = 40\n","print(label_list[datas[img_num][1]])\n","plt.imshow(datas[img_num][0])"],"metadata":{"id":"x8cyX64nvjBx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 関数の設定\n","class Discriminator(nn.Module):\n","    def __init__(self, batch_size):\n","        self.batch_size = batch_size\n","        \n","        super(Discriminator, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n","        self.bn4 = nn.BatchNorm2d(256)\n","        self.fc = nn.Linear(256*2*2, 1)\n","        \n","    def forward(self, x):\n","        x = F.avg_pool2d(F.leaky_relu(self.bn1(self.conv1(x)), 0.2, inplace=True), 2)\n","        x = F.avg_pool2d(F.leaky_relu(self.bn2(self.conv2(x)), 0.2, inplace=True), 2)\n","        x = F.avg_pool2d(F.leaky_relu(self.bn3(self.conv3(x)), 0.2, inplace=True), 2)\n","        x = F.avg_pool2d(F.leaky_relu(self.bn4(self.conv4(x)), 0.2, inplace=True), 2)\n","        x = self.fc(x.view(self.batch_size, -1))\n","        return x\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.convt1 = nn.ConvTranspose2d(128, 256, kernel_size=4, stride=1, padding=0, bias=False)\n","        self.bn1 = nn.BatchNorm2d(256)\n","        self.convt2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2, padding=0, bias=False)\n","        self.bn2 = nn.BatchNorm2d(128)\n","        self.convt3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2, padding=0, bias=False)\n","        self.bn3 = nn.BatchNorm2d(64)\n","        self.convt4 = nn.ConvTranspose2d(64, 3, kernel_size=2, stride=2, padding=0, bias=False)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.convt1(x)), inplace=True)\n","        x = F.relu(self.bn2(self.convt2(x)), inplace=True)\n","        x = F.relu(self.bn3(self.convt3(x)), inplace=True)\n","        x = torch.tanh(self.convt4(x))\n","        return x"],"metadata":{"id":"1n-nKdatvmsx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# モデル生成\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model_g = Generator().to(device)\n","print(model_g)\n","model_d = Discriminator(batch_size).to(device)\n","print(model_d)"],"metadata":{"id":"g2UmyEKJvvni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# モデル生成\n","crit = nn.BCEWithLogitsLoss()\n","\n","opt_g = optim.Adam(model_g.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","opt_d = optim.Adam(model_d.parameters(), lr=0.0002, betas=(0.5, 0.999))"],"metadata":{"id":"QqNTuiUSv2aD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 学習\n","const_z = torch.randn(64, 128, 1, 1).to(device)\n","loss_list = []\n","for e in range(1, epochs+1):\n","    model_g.train()\n","    model_d.train()\n","    running_loss_g = 0.0\n","    running_loss_d = 0.0\n","    for i, (real_img, _) in enumerate(dataloader):\n","        if len(real_img) != batch_size:\n","            continue\n","\n","        ones = torch.ones(batch_size, dtype=torch.float).view(batch_size, 1).to(device)\n","        zeros = torch.zeros(batch_size, dtype=torch.float).view(batch_size, 1).to(device)\n","            \n","        # Generatorの学習\n","        z = torch.randn(batch_size, 128, 1, 1).to(device)\n","        fake_img = model_g(z)\n","        fake_output = model_d(fake_img)\n","        loss_g = crit(fake_output, ones)\n","\n","        model_g.zero_grad()\n","        loss_g.backward()\n","        opt_g.step()\n","        \n","        # Discriminatorの学習\n","        real_img = real_img.to(device)\n","        real_output = model_d(real_img)\n","        real_loss_d = crit(real_output, ones)\n","\n","        fake_output = model_d(fake_img.detach())\n","        fake_loss_d = crit(fake_output, zeros)            \n","        loss_d = real_loss_d + fake_loss_d\n","\n","        model_d.zero_grad()\n","        loss_d.backward()\n","        opt_d.step()\n","\n","        running_loss_g += loss_g.item()\n","        running_loss_d += loss_d.item()\n","\n","        if i%20 == 0:\n","            print('[Epoch:{}/{}][{}/{}] Loss_g:{:.5f} Loss_d:{:.5f}'.format(e, epochs, i, int(len(dataloader)), loss_g.item(), loss_d.item()))\n","    \n","    loss_list.append([running_loss_g/int(len(dataloader)), running_loss_d/int(len(dataloader))])\n","    if e%5 == 0:\n","        model_g.eval()\n","        print('save img of epoch {}'.format(e))\n","        if not os.path.exists(\"save_images\"):\n","            os.mkdir(\"save_images\")\n","        output_img = model_g(const_z)\n","        save_image(output_img, \"save_images/{}.jpg\".format(e))"],"metadata":{"id":"RclWcoJ1v7YD"},"execution_count":null,"outputs":[]}]}