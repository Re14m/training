{"cells":[{"cell_type":"code","execution_count":null,"id":"3c759571","metadata":{"scrolled":true,"id":"3c759571","outputId":"9612b499-ff2e-4fac-c1d4-ca9fd210ccac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in c:\\users\\isk\\anaconda3\\lib\\site-packages (1.20.3)\n","Requirement already satisfied: pandas in c:\\users\\isk\\anaconda3\\lib\\site-packages (1.3.4)\n","Requirement already satisfied: numpy>=1.17.3 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n","Requirement already satisfied: pytz>=2017.3 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n","Requirement already satisfied: scipy in c:\\users\\isk\\anaconda3\\lib\\site-packages (1.7.1)\n","Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from scipy) (1.20.3)\n","Requirement already satisfied: scikit-learn in c:\\users\\isk\\anaconda3\\lib\\site-packages (0.24.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n","Requirement already satisfied: numpy>=1.13.3 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from scikit-learn) (1.20.3)\n","Requirement already satisfied: scipy>=0.19.1 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.1)\n","Requirement already satisfied: joblib>=0.11 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n","Requirement already satisfied: gensim in c:\\users\\isk\\anaconda3\\lib\\site-packages (4.1.2)\n","Requirement already satisfied: numpy>=1.17.0 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n","Requirement already satisfied: scipy>=0.18.1 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n","Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n","Requirement already satisfied: Cython==0.29.23 in c:\\users\\isk\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n"]}],"source":["#ライブラリのインストール\n","!pip install numpy\n","!pip install pandas\n","!pip install scipy\n","!pip install scikit-learn\n","!pip install gensim"]},{"cell_type":"code","execution_count":null,"id":"068277df","metadata":{"id":"068277df"},"outputs":[],"source":["#ライブラリのインポート\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"fbaecc02","metadata":{"id":"fbaecc02"},"outputs":[],"source":["# train.csvを読み込んで、データフレームに格納するためのプログラム\n","train_df = pd.read_csv('C:/Users/isk/workspace/2022/fake-news/train.csv')"]},{"cell_type":"code","execution_count":null,"id":"34574649","metadata":{"id":"34574649"},"outputs":[],"source":["#モデルの構築・予測\n","#データの準備\n","from sklearn.model_selection import train_test_split\n","\n","# 学習用のデータとテスト用のデータを分けるコード\n","# train_df['text']は文章、train_df['label']はそのラベルとなっているので、これらを使用します。\n","X_train, X_test, y_train, y_test = train_test_split(\n","    train_df['text'].values.astype('str'), train_df['label'].values.astype('int'), test_size=0.2, random_state=0)"]},{"cell_type":"code","execution_count":null,"id":"98bf8c66","metadata":{"id":"98bf8c66"},"outputs":[],"source":["#特徴量の選出\n","#文章からTF-IDFへの変換\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# 70%以上出てきている単語を消去し、英語のストップワード辞書に含まれている単語も削除\n","vectrizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n","\n","#学習用・テスト用それぞれの文章をTF-IDFの値に変換\n","tfidf_train = vectrizer.fit_transform(X_train).toarray()\n","tfidf_test = vectrizer.transform(X_test).toarray()"]},{"cell_type":"code","execution_count":null,"id":"1ba5cce0","metadata":{"id":"1ba5cce0"},"outputs":[],"source":["#文章からDoc2Vecへの変換\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","\n","# 学習用・テスト用それぞれにおいて単語を要素に持つリストを作成\n","word_train = [text.split(' ') for text in X_train]\n","word_test = [text.split(' ') for text in X_test]\n","\n","# 学習用の文章を学習させる\n","documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(word_train)]\n","model = Doc2Vec(documents, vector_size=300, window=20, min_count=5, workers=30)\n","\n","# 学習させた結果から、学習用・テスト用の文章をベクトル表現に変換\n","doc_train = [model.infer_vector(word) for word in word_train]\n","doc_test = [model.infer_vector(word) for word in word_test]"]},{"cell_type":"code","execution_count":null,"id":"c97501a2","metadata":{"id":"c97501a2"},"outputs":[],"source":["#学習\n","from sklearn.linear_model import LogisticRegression\n","\n","logist_tfidf = LogisticRegression()\n","logist_doc = LogisticRegression()\n","\n","# ロジスティック回帰モデルによってTF-IDFを学習させる。\n","logist_tfidf.fit(tfidf_train, y_train)\n","\n","# ロジスティック回帰モデルによってDoc2Vecを学習させる\n","logist_doc.fit(doc_train, y_train)"]},{"cell_type":"code","execution_count":null,"id":"032df64e","metadata":{"id":"032df64e"},"outputs":[],"source":["#予測\n","# 学習したモデルを用いてTF-IDFから予測する。\n","y_pred_tfidf = logist_tfidf.predict(tfidf_test)\n","\n","# 学習したモデルを用いてDoc2Vecから予測する。\n","y_pred_doc = logist_doc.predict(doc_test)"]},{"cell_type":"code","execution_count":null,"id":"c979b62d","metadata":{"id":"c979b62d"},"outputs":[],"source":["#結果の確認\n","from sklearn.metrics import confusion_matrix\n","\n","def make_conf_matrix(y_true: list, y_pred: list):\n","    '''\n","    実際のラベルと予測したラベルから、混同行列をデータフレームとして表示する関数。\n","    '''\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    cm_dict = {\n","      'フェイクニュース': {\n","        'フェイクニュース判定': cm[1][1],\n","        '正常なニュース判定': cm[1][0]\n","      },\n","      '正常なニュース':{\n","        'フェイクニュース判定': cm[0][1],\n","        '正常なニュース判定': cm[0][0]\n","      }\n","    }\n","\n","    df = pd.DataFrame(cm_dict)\n","    return df"]},{"cell_type":"code","execution_count":null,"id":"ce3e150a","metadata":{"id":"ce3e150a","outputId":"e8cf7f49-9819-4a74-80e3-7ac77c47a92f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>フェイクニュース</th>\n","      <th>正常なニュース</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>フェイクニュース判定</th>\n","      <td>2010</td>\n","      <td>125</td>\n","    </tr>\n","    <tr>\n","      <th>正常なニュース判定</th>\n","      <td>104</td>\n","      <td>1921</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            フェイクニュース  正常なニュース\n","フェイクニュース判定      2010      125\n","正常なニュース判定        104     1921"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# TF-IDFを用いた結果を表示\n","make_conf_matrix(y_test, y_pred_tfidf)"]},{"cell_type":"code","execution_count":null,"id":"40f73344","metadata":{"id":"40f73344","outputId":"e617fb12-cfba-4732-88a2-c9a632539133"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>フェイクニュース</th>\n","      <th>正常なニュース</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>フェイクニュース判定</th>\n","      <td>2060</td>\n","      <td>148</td>\n","    </tr>\n","    <tr>\n","      <th>正常なニュース判定</th>\n","      <td>54</td>\n","      <td>1898</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            フェイクニュース  正常なニュース\n","フェイクニュース判定      2060      148\n","正常なニュース判定         54     1898"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Doc2Vecを用いた結果を表示\n","make_conf_matrix(y_test, y_pred_doc)"]},{"cell_type":"code","execution_count":null,"id":"07ea1c18","metadata":{"id":"07ea1c18"},"outputs":[],"source":["#正解率,適合率,再現率,F1値の確認　\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","\n","def show_scores(y_true: list, y_pred: list):\n","    '''\n","    実際のラベルと予測したラベルから、正解率・適合率・再現率・F1値を出力する関数。\n","    ''' \n","    #それぞれのスコアを出すためのコード \n","    acc_score = accuracy_score(y_true, y_pred)\n","    prec_score = precision_score(y_true, y_pred)\n","    rec_score = recall_score(y_true, y_pred)\n","    f_score = f1_score(y_true, y_pred)\n","    \n","    print('正解率: {:.2f}%'.format(acc_score*100))\n","    print('適合率: {:.2f}%'.format(prec_score*100))\n","    print('再現率: {:.2f}%'.format(rec_score*100))\n","    print('F1値: {:.2f}%'.format(f_score*100))"]},{"cell_type":"code","execution_count":null,"id":"9e98796c","metadata":{"id":"9e98796c","outputId":"509a3204-fbd1-4257-8775-cad4ae94818e"},"outputs":[{"name":"stdout","output_type":"stream","text":["正解率: 94.50%\n","適合率: 94.15%\n","再現率: 95.08%\n","F1値: 94.61%\n"]}],"source":["#TF-IDFを用いた結果の可視化\n","show_scores(y_test, y_pred_tfidf)"]},{"cell_type":"code","execution_count":null,"id":"6c6acb84","metadata":{"id":"6c6acb84","outputId":"5898fa39-8570-44ea-e25b-8a0b0a669659"},"outputs":[{"name":"stdout","output_type":"stream","text":["正解率: 95.14%\n","適合率: 93.30%\n","再現率: 97.45%\n","F1値: 95.33%\n"]}],"source":["#Doc2Vecを用いた結果の可視化\n","show_scores(y_test, y_pred_doc)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"2022-03-03_recipie307.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}