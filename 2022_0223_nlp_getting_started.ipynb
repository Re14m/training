{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022-0223_nlp-getting-started.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1TspSzSez4auOYs1H27Bnqzzp5gmuaCr9",
      "authorship_tag": "ABX9TyOCaR7EzOog257NOAqjb3T8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Re14m/isk/blob/master/2022_0223_nlp_getting_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwtbV8EXoGzX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6424a89-d799-430b-ac5a-262d379c0b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Google Drive„Çí„Éû„Ç¶„É≥„Éà\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GoogleDrive„ÅÆKaggle„Éï„Ç©„É´„ÉÄ„ÅÆ‰∏≠„Å´„ÄÅ[„Ç≥„É≥„ÉöÂêç]„ÅÆ„Éï„Ç©„É´„ÉÄ„Çí‰Ωú„Çã"
      ],
      "metadata": {
        "id": "LS7NiauPpfCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kaggle„ÅÆ„Ç≥„É≥„Éö„Éá„Éº„Çø„ÅÆzip„Çí[„Ç≥„É≥„ÉöÂêç„Éï„Ç©„É´„ÉÄ]„Å´ÂÖ•„Çå„Çã"
      ],
      "metadata": {
        "id": "rMJ7JWyWp4_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#„Ç≥„É≥„Éö„ÅÆzip„Çí„Ç≥„Éî„Éº\n",
        "!cp \"/content/drive/MyDrive/Kaggle/nlp-getting-started/nlp-getting-started.zip\" ."
      ],
      "metadata": {
        "id": "n83Hm0AdpHHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#zip„ÇíÂ±ïÈñã\n",
        "!unzip -o /content/drive/MyDrive/Kaggle/nlp-getting-started/nlp-getting-started.zip -d ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUisirdSIO3c",
        "outputId": "1153ae46-60e9-4d5a-8b2d-2790dc9c022b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Kaggle/nlp-getting-started/nlp-getting-started.zip\n",
            "  inflating: ./sample_submission.csv  \n",
            "  inflating: ./test.csv              \n",
            "  inflating: ./train.csv             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#„É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Éù„Éº„Éà\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import defaultdict\n",
        "from collections import  Counter\n",
        "plt.style.use('ggplot')\n",
        "stop=set(stopwords.words('english'))\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "import string\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\n",
        "from keras.initializers import Constant\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qn6ZbLAdefi",
        "outputId": "5ffdd0d8-f61a-40c6-db40-d1f0bf58b89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet= pd.read_csv('train.csv')\n",
        "test=pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "0s70KAq4eBYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([tweet,test])\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9W8zQ80epbc",
        "outputId": "fb30ba6b-8d51-4d78-d83e-f413cf7d374e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10876, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"New competition launched :https://www.kaggle.com/c/nlp-getting-started\"\n",
        "\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'', text)\n",
        "\n",
        "remove_URL(example)\n",
        "df['text'] = df['text'].apply(lambda x : remove_URL(x))"
      ],
      "metadata": {
        "id": "VFahEKXFeuYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"\"\"<div>\n",
        "<h1>Real or Fake</h1>\n",
        "<p>Kaggle </p>\n",
        "<a href=\"https://www.kaggle.com/c/nlp-getting-started\">getting started</a>\n",
        "</div>\"\"\"\n",
        "\n",
        "def remove_html(text):\n",
        "    html = re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)\n",
        "print(remove_html(example))\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x : remove_html(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBGLU14Vex1Q",
        "outputId": "0bdd9c83-bae2-47d3-cbf3-d4d8360f059d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Real or Fake\n",
            "Kaggle \n",
            "getting started\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "remove_emoji(\"Omg another Earthquake üòîüòî\")\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: remove_emoji(x))"
      ],
      "metadata": {
        "id": "TFUv4L26e1Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punct(text):\n",
        "    table = str.maketrans('','', string.punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "example = \"I am a #king\"\n",
        "print(remove_punct(example))\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x : remove_punct(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QZZhCBPe5BB",
        "outputId": "759d14eb-4cfa-49ae-c4cf-63ba3bfab395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am a king\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB6WF6NAe77w",
        "outputId": "acc797d0-5b1e-40bb-c04f-291c37df4852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.6.3-py3-none-any.whl (2.7 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.7 MB 5.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker()\n",
        "def correct_spellings(text):\n",
        "    corrected_text = []\n",
        "    misspelled_words = spell.unknown(text.split())\n",
        "    for word in text.split():\n",
        "        if word in misspelled_words:\n",
        "            corrected_text.append(spell.correction(word))\n",
        "        else:\n",
        "            corrected_text.append(word)\n",
        "    return \" \".join(corrected_text)\n",
        "        \n",
        "text = \"corect me plese\"\n",
        "correct_spellings(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RK7XaKiLfCin",
        "outputId": "283f2a04-c006-4411-f935-c40685977952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'correct me plese'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_corpus(df):\n",
        "    corpus=[]\n",
        "    for tweet in tqdm(df['text']):\n",
        "        words=[word.lower() for word in word_tokenize(tweet) if((word.isalpha()==1) & (word not in stop))]\n",
        "        corpus.append(words)\n",
        "    return corpus\n",
        "\n",
        "corpus = create_corpus(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBIm0J7LfPc7",
        "outputId": "c151f49d-b7eb-4216-be85-288f5fd3b0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10876/10876 [00:04<00:00, 2292.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#„Ç≥„É≥„Éö„ÅÆ„Éï„Ç©„É´„ÉÄ„Å´„Äåhttps://www.kaggle.com/re1am0/notebook0fffe9debf/data?select=glove.6B.100d.txt„Äç„ÇíDL"
      ],
      "metadata": {
        "id": "b2Pk5q8Sf0Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#glove.6B.100d.txt.zip„Çí„Ç≥„Éî„Éº\n",
        "!cp \"/content/drive/MyDrive/Kaggle/nlp-getting-started/glove.6B.100d.txt.zip\" ."
      ],
      "metadata": {
        "id": "zdkCuLKIfxfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#glove.6B.100d.txt.zip„ÇíÂ±ïÈñã\n",
        "!unzip -o \"/content/drive/MyDrive/Kaggle/nlp-getting-started/glove.6B.100d.txt.zip\" -d."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH4KsvEvgO6U",
        "outputId": "d1c8b374-a4ae-459f-ae8a-2ba3b8be5881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Kaggle/nlp-getting-started/glove.6B.100d.txt.zip\n",
            "  inflating: ./glove.6B.100d.txt     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#glove.6B.100d.txt„Çí‰Ωø„ÅÜ\n",
        "embedding_dict={}\n",
        "with open('glove.6B.100d.txt','r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vectors = np.asarray(values[1:],'float32')\n",
        "        embedding_dict[word]  =vectors\n",
        "f.close()\n",
        "\n",
        "MAX_LEN = 50\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(corpus)\n",
        "sequences = tokenizer_obj.texts_to_sequences(corpus)\n",
        "\n",
        "tweet_pad = pad_sequences(sequences, maxlen=MAX_LEN, truncating='post', padding='post')\n",
        "\n",
        "word_index = tokenizer_obj.word_index\n",
        "print('Number of unique words:',len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJrXIE1dihaf",
        "outputId": "e653b93f-0533-434c-b1f6-fc3056ad23f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words: 20342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(word_index) + 1\n",
        "embedding_matrix = np.zeros((num_words, 100))\n",
        "\n",
        "for word,i in tqdm(word_index.items()):\n",
        "    if i > num_words:\n",
        "        continue\n",
        "    \n",
        "    emb_vec = embedding_dict.get(word)\n",
        "    if emb_vec is not None:\n",
        "        embedding_matrix[i] = emb_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp_bzJ90iowY",
        "outputId": "af5762dd-b37a-4a48-eb21-518fffed9d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20342/20342 [00:00<00:00, 307391.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "embedding=Embedding(num_words, 100, embeddings_initializer=Constant(embedding_matrix),\n",
        "                   input_length=MAX_LEN, trainable=False)\n",
        "\n",
        "model.add(embedding)\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimzer = Adam(learning_rate=1e-5)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRNn8MCfi6YY",
        "outputId": "275b2263-9dd4-4f0f-9f6b-8dcd415bcb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 100)           2034300   \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 50, 100)          0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                42240     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,076,605\n",
            "Trainable params: 42,305\n",
            "Non-trainable params: 2,034,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=tweet_pad[:tweet.shape[0]]\n",
        "test=tweet_pad[tweet.shape[0]:]\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(train,tweet['target'].values,test_size=0.15)\n",
        "print('Shape of train',X_train.shape)\n",
        "print(\"Shape of Validation \",X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdpM1bz7i_KP",
        "outputId": "e635426f-828a-4439-aae3-f797091287c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train (6471, 50)\n",
            "Shape of Validation  (1142, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train,y_train,batch_size=4,epochs=15,validation_data=(X_test,y_test),verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvrzyfsbjGTh",
        "outputId": "09428da1-22c6-4933-c7e0-a4a6288ab953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1618/1618 - 529s - loss: 0.6912 - accuracy: 0.5653 - val_loss: 0.6869 - val_accuracy: 0.5884 - 529s/epoch - 327ms/step\n",
            "Epoch 2/15\n",
            "1618/1618 - 508s - loss: 0.6355 - accuracy: 0.6390 - val_loss: 0.5545 - val_accuracy: 0.7925 - 508s/epoch - 314ms/step\n",
            "Epoch 3/15\n",
            "1618/1618 - 499s - loss: 0.5585 - accuracy: 0.7534 - val_loss: 0.5132 - val_accuracy: 0.7776 - 499s/epoch - 309ms/step\n",
            "Epoch 4/15\n",
            "1618/1618 - 497s - loss: 0.5343 - accuracy: 0.7586 - val_loss: 0.4935 - val_accuracy: 0.7916 - 497s/epoch - 307ms/step\n",
            "Epoch 5/15\n",
            "1618/1618 - 494s - loss: 0.5274 - accuracy: 0.7534 - val_loss: 0.4777 - val_accuracy: 0.8004 - 494s/epoch - 306ms/step\n",
            "Epoch 6/15\n",
            "1618/1618 - 498s - loss: 0.5104 - accuracy: 0.7648 - val_loss: 0.4667 - val_accuracy: 0.8039 - 498s/epoch - 308ms/step\n",
            "Epoch 7/15\n",
            "1618/1618 - 502s - loss: 0.5006 - accuracy: 0.7742 - val_loss: 0.4603 - val_accuracy: 0.8021 - 502s/epoch - 310ms/step\n",
            "Epoch 8/15\n",
            "1618/1618 - 493s - loss: 0.5008 - accuracy: 0.7725 - val_loss: 0.4584 - val_accuracy: 0.8100 - 493s/epoch - 305ms/step\n",
            "Epoch 9/15\n",
            "1618/1618 - 498s - loss: 0.4965 - accuracy: 0.7756 - val_loss: 0.4521 - val_accuracy: 0.8082 - 498s/epoch - 308ms/step\n",
            "Epoch 10/15\n",
            "1618/1618 - 495s - loss: 0.4938 - accuracy: 0.7775 - val_loss: 0.4490 - val_accuracy: 0.8091 - 495s/epoch - 306ms/step\n",
            "Epoch 11/15\n",
            "1618/1618 - 495s - loss: 0.4857 - accuracy: 0.7806 - val_loss: 0.4448 - val_accuracy: 0.8039 - 495s/epoch - 306ms/step\n",
            "Epoch 12/15\n",
            "1618/1618 - 500s - loss: 0.4858 - accuracy: 0.7799 - val_loss: 0.4434 - val_accuracy: 0.8021 - 500s/epoch - 309ms/step\n",
            "Epoch 13/15\n",
            "1618/1618 - 500s - loss: 0.4757 - accuracy: 0.7852 - val_loss: 0.4397 - val_accuracy: 0.8135 - 500s/epoch - 309ms/step\n",
            "Epoch 14/15\n",
            "1618/1618 - 497s - loss: 0.4792 - accuracy: 0.7858 - val_loss: 0.4378 - val_accuracy: 0.8161 - 497s/epoch - 307ms/step\n",
            "Epoch 15/15\n",
            "1618/1618 - 501s - loss: 0.4779 - accuracy: 0.7826 - val_loss: 0.4370 - val_accuracy: 0.8187 - 501s/epoch - 309ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub=pd.read_csv('sample_submission.csv')\n",
        "\n",
        "y_pre = model.predict(test)\n",
        "y_pre = np.round(y_pre).astype(int).reshape(3263)\n",
        "sub = pd.DataFrame({'id':sample_sub['id'].values.tolist(), 'target':y_pre})\n",
        "sub.to_csv('submission.csv',index=False)"
      ],
      "metadata": {
        "id": "MjuNDwbHjJiq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}