{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022-0404_recipie086.ipynb","provenance":[],"collapsed_sections":[],"private_outputs":true,"authorship_tag":"ABX9TyMRbUkg59zvGgc2FeNlKDWT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aa4z5EjZwove"},"outputs":[],"source":["# GC mount\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# dataset DL(https://drive.google.com/open?id=1TfHtRoX73yIJd40QNLEhYzgH_wlhQSLz)\n","# dataset コピー\n","!cp \"/content/drive/MyDrive/Colab Notebooks/note_Axross/tr-music-dataset.rar\" /content/\n","# dataset 解凍\n","!unrar x tr-music-dataset.rar"],"metadata":{"id":"nqSig8QsxOsA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ライブラリのインポート\n","\n","# feature extractoring and preprocessing data\n","import librosa\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import os\n","from PIL import Image\n","import pathlib\n","import csv\n","from tqdm import tqdm\n","\n","# Preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","\n","# Keras\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"une70UgzxHEA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# モデル生成（1次元分類、音響的特徴量をdata.csvに変換）\n","header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n","for i in range(1, 21):\n","    header += f' mfcc{i}'\n","header += ' label'\n","header = header.split()\n","\n","moods = 'angry happy relax sad'.split()\n","file = open('data.csv', 'w', newline='')\n","with file:\n","    writer = csv.writer(file)\n","    writer.writerow(header)\n","for g in moods:\n","    for filename in tqdm(os.listdir(f'./tr-music-dataset/{g}')):\n","        songname = f'./tr-music-dataset/{g}/{filename}'\n","        y, sr = librosa.load(songname, mono=True, duration=30)\n","        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n","        # rmse = librosa.feature.rmse(y=y)\n","        rmse = librosa.feature.rms(y=y) # librosaのバージョンが0.7.0以上の場合はこちらを実行\n","        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n","        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n","        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n","        zcr = librosa.feature.zero_crossing_rate(y)\n","        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n","        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n","        for e in mfcc:\n","            to_append += f' {np.mean(e)}'\n","        to_append += f' {g}'\n","        file = open('data.csv', 'a', newline='')\n","        with file:\n","            writer = csv.writer(file)\n","            writer.writerow(to_append.split())"],"metadata":{"id":"_fbxmJwvyRUJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 特徴量データの確認\n","data = pd.read_csv('data.csv', usecols=range(0, 28))\n","data = data[data['label'].isin(moods)].reset_index(drop=True)\n","data.head()"],"metadata":{"id":"B1RMV4ZQzC6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 特徴量データのファイルサイズ確認\n","data.shape"],"metadata":{"id":"mchAwqBuzUgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 不要データ列の削除\n","data = data.drop(['filename'],axis=1)"],"metadata":{"id":"Td7atk59zhAx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 学習データ・正解データの加工\n","genre_list = data.iloc[:, -1]\n","encoder = LabelEncoder()\n","y = encoder.fit_transform(genre_list)"],"metadata":{"id":"KnEOsFmuztov"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# データの正規化\n","scaler = StandardScaler()\n","X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"],"metadata":{"id":"c_qdLMoMz3R8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# データの分離\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"],"metadata":{"id":"APJkSmgq52ct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 学習モデルの作成\n","from keras import models\n","from keras import layers\n","\n","model = models.Sequential()\n","model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(4, activation='softmax'))"],"metadata":{"id":"BVNakSKB5_c6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# モデルのコンパイル\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"TnofqSMJ6C-d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# モデルの保存\n","history = model.fit(X_train,\n","                    y_train,\n","                    epochs=20,\n","                    validation_data=(X_test,y_test),\n","                    batch_size=20)"],"metadata":{"id":"VktGOG1n83eT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 推論データ(https://drive.google.com/file/d/1hHKyQsjOPDijk89OM_bZwv4MrQQAV7U2/view?usp=sharing)\n","\n","# 推論データ特徴量書出し\n","file = open('test.csv', 'w', newline='')\n","with file:\n","    writer = csv.writer(file)\n","    writer.writerow(header)\n","\n","filename = 'test.mp3'\n","y, sr = librosa.load(filename, mono=True, duration=30)\n","chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n","rmse = librosa.feature.rms(y=y)\n","spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n","spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n","rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n","zcr = librosa.feature.zero_crossing_rate(y)\n","mfcc = librosa.feature.mfcc(y=y, sr=sr)\n","to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'  \n","for e in mfcc:\n","    to_append += f' {np.mean(e)}'\n","\n","file = open('test.csv', 'a', newline='')\n","with file:\n","    writer = csv.writer(file)\n","    writer.writerow(to_append.split())"],"metadata":{"id":"0UEao0JL9E1m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 推論（モデル利用）\n","test = pd.read_csv('test.csv')\n","test = test.drop(['filename'],axis=1)\n","\n","scaler = StandardScaler()\n","X = scaler.fit_transform(np.array(test.iloc[:, :-1], dtype = float))\n","\n","predictions = model.predict(X)\n","print(predictions)\n","np.argmax(predictions[0])"],"metadata":{"id":"twSWa1iT9vyv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# スペクトログラム（値変換による画像化）\n","cmap = plt.get_cmap('inferno')\n","\n","plt.figure(figsize=(10,10))\n","moods = 'angry happy relax sad'.split()\n","for g in tqdm(moods):\n","    i = 0\n","    os.makedirs(f'img_data/train/{g}', exist_ok=True)\n","    os.makedirs(f'img_data/test/{g}', exist_ok=True)\n","    for filename in os.listdir(f'./tr-music-dataset/{g}'):\n","        i = i + 1\n","        songname = f'./tr-music-dataset/{g}/{filename}'\n","        y, sr = librosa.load(songname, mono=True, duration=5)\n","        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n","        plt.axis('off');\n","        if i % 5 != 0:\n","            plt.savefig(f'img_data/train/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n","        else:\n","            plt.savefig(f'img_data/test/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n","        plt.clf()"],"metadata":{"id":"JeybJ7Qg-EWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 学習データの加工\n","train_datagen = ImageDataGenerator(\n","    rescale = 1.0 / 255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip = True\n",")"],"metadata":{"id":"jRt-dMlg-WCf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 学習データの加工\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras import models, optimizers\n","from keras.layers import Input, Dense, Dropout, Activation, Flatten\n","from keras.preprocessing.image import load_img,ImageDataGenerator\n","from keras.callbacks import CSVLogger , ModelCheckpoint\n","\n","image_size = 224\n","batch_size = 20\n","\n","train_dir = 'img_data/train/'\n","test_dir = 'img_data/test/'\n","\n","train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n","validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(image_size, image_size),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=True\n",")\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(image_size, image_size),\n","    batch_size=20,\n","    class_mode='categorical',\n","    shuffle=True\n",")"],"metadata":{"id":"nx4VgJPCAojv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FineTuning, モデル作成\n","vgg_conv = VGG16(weights='imagenet', include_top=False,\n","                 input_shape=(image_size, image_size, 3))\n","for layer in vgg_conv.layers[:-4]:\n","    layer.trainable = True\n","\n","model = models.Sequential()\n","model.add(vgg_conv)\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(4, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"2DKYVENvA5xb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 学習の実行とモデルの保存\n","hist=model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=16,\n","    epochs=20,\n","    verbose=1,\n","    validation_data=validation_generator,\n","    validation_steps=4\n",")\n","\n","model.save('music_classification.h5')"],"metadata":{"id":"V_nxCh6PBATT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 推論\n","\n","# スペクトログラムファイル作成\n","cmap = plt.get_cmap('inferno')\n","filename = 'test.mp3'\n","plt.figure(figsize=(10,10))\n","pathlib.Path(f'img_data').mkdir(parents=True, exist_ok=True)     \n","y, sr = librosa.load(filename, mono=True, duration=5)\n","plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n","plt.axis('off');\n","plt.savefig(f'img_data/{filename[:-3].replace(\".\", \"\")}.png')\n","plt.clf()"],"metadata":{"id":"U-2LH_IzCOeF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 推論\n","from keras.applications.vgg16 import preprocess_input\n","from keras.preprocessing.image import load_img, img_to_array\n","\n","filename = 'img_data/test.png'\n","image = load_img(filename, target_size=(224, 224))\n","image = img_to_array(image)\n","image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","image = preprocess_input(image)\n","predictions = model.predict(image)\n","np.argmax(predictions[0])"],"metadata":{"id":"Q0auUjreCWPs"},"execution_count":null,"outputs":[]}]}