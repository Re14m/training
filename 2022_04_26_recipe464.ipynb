{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022-04-26_recipe464.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfvd5OyhSg5Xa60v55700Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Re14m/training/blob/master/2022_04_26_recipe464.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVqg5RaUb7TS"
      },
      "outputs": [],
      "source": [
        "# 画像データセットのダウンロード（https://github.com/albumentations-team/albumentations）\n",
        "!wget \"https://drive.google.com/uc?export=download&id=1rVD5yS_BI4wd_IBlHXKhRNTpLU6oCaN2\" -O sample.jpg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DLした画像の表示\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "image = cv2.imread('sample.jpg')\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "yOgm-yHsdV-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリのインストール\n",
        "!pip install -U albumentations\n",
        "!pip install \"opencv-python-headless<4.3\""
      ],
      "metadata": {
        "id": "4-FaEgtHdaaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Albumentationsのデータ拡張をリスト化\n",
        "import albumentations as A\n",
        "\n",
        "ops = [\n",
        "    A.HorizontalFlip(p=1.0), # 水平反転\n",
        "    A.RandomRotate90(p=1.0), # ランダム90度回転\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.5, p=1.0),  # ランダム輝度・コントラスト変更\n",
        "]"
      ],
      "metadata": {
        "id": "uz3vL8u3mWA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# リストを引数に渡す\n",
        "transforms = A.Compose(ops)"
      ],
      "metadata": {
        "id": "0tlxL3USmebD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データ拡張の実施\n",
        "augment_image = transforms(image=image)"
      ],
      "metadata": {
        "id": "dZhPnMp1mku1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 結果の表示\n",
        "cv2_imshow(augment_image[\"image\"])"
      ],
      "metadata": {
        "id": "lL09fYGympk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OneOfを使うことでリストのうちの1枚を取り出す\n",
        "transforms = A.OneOf(ops, p=1.0)\n",
        "augment_image = transforms(image=image)\n",
        "\n",
        "# 結果の表示\n",
        "cv2_imshow(augment_image[\"image\"])"
      ],
      "metadata": {
        "id": "HLpiBVNxzDwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datasetのダウンロード\n",
        "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip -O kagglecatsanddogs_3367a.zip"
      ],
      "metadata": {
        "id": "kDPUzbKOzL-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datasetの解凍\n",
        "!unzip kagglecatsanddogs_3367a.zip"
      ],
      "metadata": {
        "id": "FQ77jXQSzsKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 下準備1\n",
        "from glob import glob\n",
        "\n",
        "# 全画像ファイルパスのリストを取得\n",
        "file_path_list = glob('PetImages/**/*.jpg', recursive=True)"
      ],
      "metadata": {
        "id": "mEq9y2mSz0D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 下準備2\n",
        "import cv2\n",
        "\n",
        "# imread()で問題なく読み込み出来た画像のみを使用する。\n",
        "correct_image_path_list = []\n",
        "for file_path in file_path_list:\n",
        "    image = cv2.imread(file_path)\n",
        "    if image is not None:\n",
        "        correct_image_path_list.append(file_path)\n",
        "    else:\n",
        "        print('Corrupted image:', file_path)"
      ],
      "metadata": {
        "id": "xfeaUJarz9TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datasetの分割\n",
        "import random\n",
        "\n",
        "# ファイルパスのリストをシャッフル\n",
        "random.seed(123)\n",
        "random.shuffle(correct_image_path_list)\n",
        "\n",
        "# 学習・検証・テストデータに分割\n",
        "train_file_path_list = correct_image_path_list[:500]\n",
        "val_file_path_list = correct_image_path_list[500:600]\n",
        "test_file_path_list = correct_image_path_list[600:610]\n",
        "\n",
        "print(len(train_file_path_list), len(val_file_path_list), len(test_file_path_list))"
      ],
      "metadata": {
        "id": "hdPBXu5_0K19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルのトレーニング（RandAugmentなし）\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "Gv1pC7S50a4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル構築（ResNet50の学習済モデル）\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# デバイス\n",
        "device = 'cuda'\n",
        "# 学習率\n",
        "learning_rate = 0.001\n",
        "\n",
        "# ResNet50学習済モデルを使用\n",
        "model = getattr(models, 'resnet50')(pretrained=False, num_classes=1)\n",
        "model = model.to(device)\n",
        "\n",
        "# 損失関数、最適化関数を定義\n",
        "criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "qmH_TaCT0luC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datasetの準備（pytorch向け）\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CatsAndDogsDataset(Dataset):\n",
        "    def __init__(self, image_file_path, transform=None):\n",
        "        # 画像データ格納パスのリスト\n",
        "        self.image_file_path = image_file_path\n",
        "        # データ変換設定\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_file_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 画像読み込み\n",
        "        image_filepath = self.image_file_path[idx]\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # ディレクトリ名からラベルを指定(Dogs：0、Cats：1)\n",
        "        if os.path.normpath(image_filepath).split(os.sep)[-2] == \"Cat\":\n",
        "            label = 1.0\n",
        "        else:\n",
        "            label = 0.0\n",
        "        \n",
        "        # transformが指定されている場合は、変換を実施\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "            \n",
        "        return image, label"
      ],
      "metadata": {
        "id": "uVeYmmHG002q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset変換関数の準備（リサイズ,正規化,Tensor形式への変換）\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "train_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=128, width=128),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=128, width=128),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Mj7jup4K1AA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データと検証データの読込\n",
        "batch_size = 128\n",
        "num_workers = 4\n",
        "\n",
        "# 学習データ\n",
        "train_dataset = CatsAndDogsDataset(image_file_path=train_file_path_list, transform=train_transform)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True,\n",
        ")\n",
        "\n",
        "# 検証データ\n",
        "val_dataset = CatsAndDogsDataset(image_file_path=val_file_path_list, transform=val_transform)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True,\n",
        ")"
      ],
      "metadata": {
        "id": "9vtqf9311Vdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練\n",
        "%%time\n",
        "\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# エポック数\n",
        "epochs = 100\n",
        "\n",
        "# ベストモデル保存用変数\n",
        "best_acc = 0\n",
        "best_model_weight = copy.deepcopy(model.state_dict())\n",
        "\n",
        "# Accuracy計算用の関数\n",
        "def calculate_accuracy(output, target):\n",
        "    output = (torch.sigmoid(output) >= 0.5)\n",
        "    target = (target == 1.0)\n",
        "    accuracy = torch.true_divide((target == output).sum(dim=0), output.size(0)).item()\n",
        "    return accuracy\n",
        "\n",
        "# トレーニング\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_acc = []\n",
        "    train_loss = []\n",
        "    val_acc = []\n",
        "    val_loss = []\n",
        "\n",
        "    # 学習\n",
        "    model.train()\n",
        "    stream = tqdm(train_loader)\n",
        "    for i, (images, target) in enumerate(stream, start=1):\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True).float().view(-1, 1)\n",
        "\n",
        "        output = model(images)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        accuracy = calculate_accuracy(output, target)\n",
        "\n",
        "        train_acc.append(accuracy)\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        log_text = 'Epoch: {epoch}. Train.      '.format(epoch=epoch)\n",
        "        log_text = log_text + \"Loss: {avg:.3f} \".format(avg=(sum(train_loss)/len(train_loss)))\n",
        "        log_text = log_text + \"Accuracy: {avg:.3f} \".format(avg=(sum(train_acc)/len(train_acc)))\n",
        "        stream.set_description(log_text)\n",
        "\n",
        "    # 検証\n",
        "    model.eval()\n",
        "    stream = tqdm(val_loader)\n",
        "    with torch.no_grad():\n",
        "        for i, (images, target) in enumerate(stream, start=1):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            target = target.to(device, non_blocking=True).float().view(-1, 1)\n",
        "\n",
        "            output = model(images)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            accuracy = calculate_accuracy(output, target)\n",
        "\n",
        "            val_acc.append(accuracy)\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "            log_text = 'Epoch: {epoch}. Validation. '.format(epoch=epoch)\n",
        "            log_text = log_text + \"Loss: {avg:.3f} \".format(avg=(sum(val_loss)/len(val_loss)))\n",
        "            log_text = log_text + \"Accuracy: {avg:.3f} \".format(avg=(sum(val_acc)/len(val_acc)))\n",
        "            stream.set_description(log_text)\n",
        "\n",
        "    # ベストモデル更新            \n",
        "    val_acc_avg = sum(val_acc)/len(val_acc)\n",
        "    if val_acc_avg > best_acc:\n",
        "        best_acc = val_acc_avg\n",
        "        best_model_weight = copy.deepcopy(model.state_dict())\n",
        "\n",
        "# ベストモデルを復元    \n",
        "model.load_state_dict(best_model_weight)"
      ],
      "metadata": {
        "id": "0t1sRP9_1f9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 精度の表示\n",
        "print(best_acc)"
      ],
      "metadata": {
        "id": "FW26foGM1lux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル構築（RandAugument）\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# デバイス\n",
        "device = 'cuda'\n",
        "# 学習率\n",
        "learning_rate = 0.001\n",
        "\n",
        "# ResNet50学習済モデルを使用\n",
        "model2 = getattr(models, 'resnet50')(pretrained=False, num_classes=1)\n",
        "model2 = model2.to(device)\n",
        "\n",
        "# 損失関数、最適化関数を定義\n",
        "criterion2 = nn.BCEWithLogitsLoss().to(device)\n",
        "optimizer2 = optim.Adam(model2.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "IhGc5HJFKTvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandAugumentation処理\n",
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "\n",
        "# オートコントラスト\n",
        "def auto_contrast(image, **kwargs):\n",
        "    image = np.float32(image)\n",
        "    hist = cv2.calcHist([image], [0], None, [256], (0, 256)).ravel()\n",
        "\n",
        "    for lo in range(256):\n",
        "        if hist[lo]:\n",
        "            break\n",
        "    for hi in range(255, -1, -1):\n",
        "        if hist[hi]:\n",
        "            break\n",
        "\n",
        "    if hi > lo:\n",
        "        lut = np.zeros(256, dtype=np.uint8)\n",
        "        scale_coef = 255.0 / (hi - lo)\n",
        "        offset = -lo * scale_coef\n",
        "        for ix in range(256):\n",
        "            lut[ix] = int(np.clip(ix * scale_coef + offset, 0, 255))\n",
        "\n",
        "        image = np.uint8(image)\n",
        "        image = cv2.LUT(image, lut)\n",
        "\n",
        "    return image\n",
        "    \n",
        "# カラーバランス調整\n",
        "def color_balance(factor):\n",
        "    def color_balance_function(image, **kwargs):\n",
        "        new_image = np.zeros(image.shape)\n",
        "        new_image[:, :, 0] = ((1 + 2 * factor) * image[:, :, 0] +\n",
        "                            (1 - factor) * image[:, :, 1] +\n",
        "                            (1 - factor) * image[:, :, 2]) / 3\n",
        "        new_image[:, :, 1] = ((1 + 2 * factor) * image[:, :, 1] +\n",
        "                            (1 - factor) * image[:, :, 0] +\n",
        "                            (1 - factor) * image[:, :, 2]) / 3\n",
        "        new_image[:, :, 2] = ((1 + 2 * factor) * image[:, :, 2] +\n",
        "                            (1 - factor) * image[:, :, 0] +\n",
        "                            (1 - factor) * image[:, :, 1]) / 3\n",
        "        new_image = np.uint8(new_image)\n",
        "        return new_image\n",
        "    return color_balance_function\n",
        "\n",
        "def create_rand_augment_ops(N, M, p):\n",
        "    # マグニチュード(M)探索空間  \n",
        "    rot = np.linspace(-30, 30, 10)\n",
        "    sola = np.linspace(0, 256, 10)\n",
        "    color_factor = np.linspace(0.1, 1.9, 10)\n",
        "    post = [4, 4, 5, 5, 6, 6, 7, 7, 8, 8]\n",
        "    cont = [np.linspace(-0.8, -0.1, 10), np.linspace(0.1, 2, 10)]\n",
        "    bright = np.linspace(0.1, 0.7, 10)\n",
        "    shar = np.linspace(0.1, 0.9, 10)\n",
        "    shear = np.linspace(0, 10, 10)\n",
        "    shift_x = np.linspace(0, 150, 10)\n",
        "    shift_y = np.linspace(0, 150, 10)\n",
        "\n",
        "    # 変換(N)探索空間\n",
        "    transform = [\n",
        "        A.NoOp(),\n",
        "        A.Lambda(image=auto_contrast),\n",
        "        A.Equalize(p=p),\n",
        "        A.Affine(rotate=rot[M], p=p),\n",
        "        A.Solarize(threshold=sola[M], p=p),\n",
        "        A.Lambda(image=color_balance(color_factor[M])),\n",
        "        A.Posterize(num_bits=post[M], p=p),\n",
        "        A.RandomBrightnessContrast(contrast_limit=[cont[0][M], cont[1][M]], p=p),\n",
        "        A.RandomBrightnessContrast(brightness_limit=bright[M], p=p),\n",
        "        A.Sharpen(alpha=shar[M], lightness=shar[M], p=p),\n",
        "        A.Affine(shear={'x':shear[M]}, p=p),\n",
        "        A.Affine(shear={'y':shear[M]}, p=p),\n",
        "        A.ShiftScaleRotate(shift_limit_x=shift_x[M], rotate_limit=0, shift_limit_y=0, shift_limit=shift_x[M], p=p),\n",
        "        A.ShiftScaleRotate(shift_limit_y=shift_y[M], rotate_limit=0, shift_limit_x=0, shift_limit=shift_y[M], p=p),\n",
        "    ]\n",
        "\n",
        "    # ランダムに選択\n",
        "    ops = np.random.choice(transform, N)\n",
        "    \n",
        "    return ops"
      ],
      "metadata": {
        "id": "4loEnDJVKbOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データ拡張用のデータローダ\n",
        "N, M = 3, 1\n",
        "p = 1.0\n",
        "\n",
        "rand_augment_ops = create_rand_augment_ops(N, M, p=p)\n",
        "train_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=128, width=128),\n",
        "        *rand_augment_ops,\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "val_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=128, width=128),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "enLyTkpWKp6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データと検証データの読込\n",
        "batch_size = 128\n",
        "num_workers = 4\n",
        "\n",
        "# 学習データ\n",
        "train_dataset = CatsAndDogsDataset(image_file_path=train_file_path_list, transform=train_transform)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True,\n",
        ")\n",
        "\n",
        "# 検証データ\n",
        "val_dataset = CatsAndDogsDataset(image_file_path=val_file_path_list, transform=val_transform)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True,\n",
        ")"
      ],
      "metadata": {
        "id": "hAklGiYNKy_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練\n",
        "%%time\n",
        "\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# エポック数\n",
        "epochs = 100\n",
        "\n",
        "# ベストモデル保存用変数\n",
        "best_acc = 0\n",
        "best_model_weight = copy.deepcopy(model.state_dict())\n",
        "\n",
        "# トレーニング\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_acc = []\n",
        "    train_loss = []\n",
        "    val_acc = []\n",
        "    val_loss = []\n",
        "\n",
        "    # 学習\n",
        "    model2.train()\n",
        "    stream = tqdm(train_loader)\n",
        "    for i, (images, target) in enumerate(stream, start=1):\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True).float().view(-1, 1)\n",
        "\n",
        "        output = model2(images)\n",
        "\n",
        "        loss = criterion2(output, target)\n",
        "        accuracy = calculate_accuracy(output, target)\n",
        "\n",
        "        train_acc.append(accuracy)\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        optimizer2.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "        log_text = 'Epoch: {epoch}. Train.      '.format(epoch=epoch)\n",
        "        log_text = log_text + \"Loss: {avg:.3f} \".format(avg=(sum(train_loss)/len(train_loss)))\n",
        "        log_text = log_text + \"Accuracy: {avg:.3f} \".format(avg=(sum(train_acc)/len(train_acc)))\n",
        "        stream.set_description(log_text)\n",
        "\n",
        "    # 検証\n",
        "    model2.eval()\n",
        "    stream = tqdm(val_loader)\n",
        "    with torch.no_grad():\n",
        "        for i, (images, target) in enumerate(stream, start=1):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            target = target.to(device, non_blocking=True).float().view(-1, 1)\n",
        "\n",
        "            output = model2(images)\n",
        "            \n",
        "            loss = criterion2(output, target)\n",
        "            accuracy = calculate_accuracy(output, target)\n",
        "\n",
        "            val_acc.append(accuracy)\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "            log_text = 'Epoch: {epoch}. Validation. '.format(epoch=epoch)\n",
        "            log_text = log_text + \"Loss: {avg:.3f} \".format(avg=(sum(val_loss)/len(val_loss)))\n",
        "            log_text = log_text + \"Accuracy: {avg:.3f} \".format(avg=(sum(val_acc)/len(val_acc)))\n",
        "            stream.set_description(log_text)\n",
        "            \n",
        "    # ベストモデル更新   \n",
        "    val_acc_avg = sum(val_acc)/len(val_acc)\n",
        "    if val_acc_avg > best_acc:\n",
        "        best_acc = val_acc_avg\n",
        "        best_model_weight = copy.deepcopy(model2.state_dict())\n",
        "\n",
        "    # RandAugmentのデータ拡張リストを再生成\n",
        "    rand_augment_ops = create_rand_augment_ops(N, M, p=p)\n",
        "    train_transform = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=128, width=128),\n",
        "            *rand_augment_ops,\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "            ToTensorV2(),\n",
        "        ]\n",
        "    )\n",
        "    train_dataset = CatsAndDogsDataset(image_file_path=train_file_path_list, transform=train_transform)\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True,\n",
        "    )\n",
        "        \n",
        "# ベストモデルを復元\n",
        "model2.load_state_dict(best_model_weight)"
      ],
      "metadata": {
        "id": "ZeMn2EYrLGa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 結果の確認（テストデータの読込）\n",
        "test_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=128, width=128),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "test_dataset = CatsAndDogsDataset(image_file_path=test_file_path_list, transform=test_transform)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True,\n",
        ")"
      ],
      "metadata": {
        "id": "JT3i4E38Fw6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 描画用関数\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_image_grid(images_file_path, predicted_labels=(), cols=5):\n",
        "    rows = len(images_file_path) // cols\n",
        "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
        "    for i, image_filepath in enumerate(images_file_path):\n",
        "        # 画像読み込み\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # 正解ラベルは緑色、不正解ラベルは赤色にする\n",
        "        true_label = os.path.normpath(image_filepath).split(os.sep)[-2]\n",
        "        predicted_label = predicted_labels[i] if predicted_labels else true_label\n",
        "        color = \"green\" if true_label == predicted_label else \"red\"\n",
        "\n",
        "        # 画像とラベル名をセット\n",
        "        ax.ravel()[i].imshow(image)\n",
        "        ax.ravel()[i].set_title(predicted_label, color=color)\n",
        "        ax.ravel()[i].set_axis_off()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ORrCC_p-F28K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 予測（RandAugumentなし）\n",
        "model = model.eval()\n",
        "\n",
        "predicted_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        # 推論\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        output = model(images)\n",
        "\n",
        "        # 推論結果のラベル生成\n",
        "        predictions = (torch.sigmoid(output) >= 0.5)[:, 0].cpu().numpy()\n",
        "        predicted_labels += [\"Cat\" if is_cat else \"Dog\" for is_cat in predictions]"
      ],
      "metadata": {
        "id": "xMEGIxipF-Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 結果の表示\n",
        "display_image_grid(test_file_path_list, predicted_labels)"
      ],
      "metadata": {
        "id": "xmr2okOpGDux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 予測（RandAugument）\n",
        "model2 = model2.eval()\n",
        "\n",
        "predicted_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        # 推論\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        output = model2(images)\n",
        "\n",
        "        # 推論結果のラベル生成\n",
        "        predictions = (torch.sigmoid(output) >= 0.5)[:, 0].cpu().numpy()\n",
        "        predicted_labels += [\"Cat\" if is_cat else \"Dog\" for is_cat in predictions]"
      ],
      "metadata": {
        "id": "ZIXyrJ4CHX73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 結果の表示\n",
        "display_image_grid(test_file_path_list, predicted_labels)"
      ],
      "metadata": {
        "id": "EBQk0lJMHbRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}